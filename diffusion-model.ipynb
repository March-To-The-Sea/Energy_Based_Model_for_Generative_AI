{"metadata":{"language_info":{"name":"python"},"kernelspec":{"name":"","display_name":""},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"def lienar_diffusion_schedule(diffusion_times):\n    min_rate = 0.0001\n    max_rate = 0.02\n    betas = min_rate + tf.convert_to_tensor(diffusion_times) * (max_rate - min_rate)\n    alphas = 1 - betas\n    alpha_bars = tf.math.cumprod(alphas)\n    signal_rates = alpha_bars\n    noise_rates = 1 - alpha_bars\n    return noise_rates, signal noise_rates\n\nT = 1000\ndiffusion_times = [x/T for x in range(T)]\nlinear_noise_rates, linear_signal_rates = lienar_diffusion_schedule(diffusion_times)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cosine_diffusion_schedule(diffusion_times):\n    signal_rates = tf.cos(diffusion_times * math.pi / 2)\n    noise_rates = tf.sin(diffusion_times * math.pi / 2)\n    return noise_rates, signal_rates\n\ndef offset_cosine_diffusion_schedule(diffusion_times):\n    min_signal_rate = 0.02\n    max_signal_rate = 0.95\n    start_angle = tf.acos(max_signal_rate)\n    end_angle = tf.acos(min_signal_rate)\n\n    diffusion_angles = start_angle + diffusion_times * (end_angle - start_angle)\n\n    signal_rates = tf.cos(diffusion_angles)\n    noise_rates = tf.sin(diffusion_angles) \n\n    return noise_rates, signal_rates","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DiffusionModel(models.Model):\n    \n    def __init__(self):\n        super().__init__()\n        self.normalizer = layers.Normalization()\n        self.network = UnicodeTranslateError\n        self.ema_network = models.clone_moel(self.network)\n        self.diffusion_schedule = cosine_diffusion_schedule\n        \n    def denoise(self, noisey_images, noise_rates, signal_rates, trainig):\n        if training:\n            network = self.network\n        else:\n            network = self.ema_network\n        pred_noises = network(\n            [noisy_images, noise_rates**2], training = training\n        )\n        pred_images = (noisy_images - noise_rates * pred_noises) / signal_rates\n\n        return pred_noises, pred_images\n    \n    def train_step(self, images):\n        images = self.normalizer(images, training = True)\n        noises = tf.random.normal(shape = tf.shape(images))\n        batch_size = tf.shape(images)[0]\n        diffusion_times = tf.random.uniform(\n            shape = (batch_size, 1, 1, 1), minval = 0.0, maxval = 1.0\n        )\n        noise_rates, signal_rates = self.cosine_diffusion_schedule(\n            diffusion_times\n        )\n        noisy_images = signal_rates * images + noise_rates * noises\n        with tf.GradientTape() as tape:\n            pred_noises, pred_images = self.denoise(\n                noisy_images, noise_rates, signal_rates, training = True\n            )\n            noise_loss = self.loss(noises, pred_noises)\n        gradients = tape.gradient(noise_loss, self.network.trainable_weights)\n        self.optimizer.apply_gradients(zip(gradients, self.network.trainable_weights))\n        self.noise_loss_tracker.update_state(noise_loss)\n\n        for weight, ema_weight in zip(self.network.weights, self.ema_network.weights):\n            ema_weight.assign(0.99 * ema_weight + (1 - 0.999) * weight)\n        \n        return {m.name: m.result() for m in self.metrics}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"noisy_images = layers.Input(shape = (64, 64, 3))\nx = layers.Conv2D(32, kernel_size = 1)(noisy_images)\n\nnoise_variances = layers.Input(shape = (1, 1, 1))\nnoise_embedding = layers.Lambda(sinusoidal_embedding)(noise_variances)\nnoise_embedding.UpSampling2D(size = 64, interpolation = \"nearest\")(noise_embedding)\n\nx = layers.Concatenate()([x, noise_embedding])\n\nskips = []\n\nx = DownBlock(32, block_depth = 2)([x, skips])\nx = DownBlock(64, block_depth = 2)([x, skips])\nx = DownBlock(96, block_depth = 2)([x, skips])\n\nx = ResidualBlock(128)(x)\nx = ResidualBlock(128)(x)\n\nx = DownBlock(96, block_depth = 2)([x, skips])\nx = DownBlock(64, block_depth = 2)([x, skips])\nx = DownBlock(32, block_depth = 2)([x, skips])\n\nx = layers.Conv2D(3, kernel_size = 1, kernel_initializer = \"zeros\")(x)\n\nunet = models.Model([noisy_images, noise_variances], x, name = \"unet\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sinusoidal_embedding(x):\n    frequencies = tf.exp(\n        tf.linspace(tf.math.log(1.0), tf.math.log(1000.0), 16,)\n    )\n    angular_speeds = 2.0 * math.pi * frequencies\n    embeddings = tf.concat(\n        [tf.sin(angular_speeds * x), tf.cos(angular_speeds * x)], axis = 3\n    )\n    return embeddings","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ResidualBlock(width):\n    def apply(x):\n        input_width = x.shape[3]\n        if input_width == width:\n            residual = x\n        else:\n            residual = layers.Conv2D(width, kernel_size = 1)(x)\n        x = layers.BatchNormalization(center = False, scale = False)(x)\n        x = layers.Conv2D(width, kernel_size = 3, padding = \"same\", activation = activations.swish)(x)\n        x = layers.Conv2D(width, kernel_size = 3, padding = \"same\")(x)\n        x = layers.Add()([x, residual])\n        return x\n    \n    return apply","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def DownBlock(width, block_depth):\n    def apply(x):\n        x, skips = x\n        for _ in range(block_depth):\n            x = ResidualBlock(width)(x)\n            skips.append(x)\n        x = layers.AveragePooling2D(pool_size = 2)(x)\n        return x\n    return apply\n\ndef UpBlock(width, block_depth):\n    def apply(x):\n        x, skips = x\n        x = layers.UpSampling2D(size = 2, interpolation = \"bilinear\")(x)\n        for _ in range(block_depth):\n            x = layers.Concatenate()([x, skips.pop()])\n            x = ResidualBlock(width)(x)\n        return x\n    \n    return apply","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = DiffusionModel()\nmodel.compile(\n    optimizer = optimizers.experimental.AdamW(learning_rate = 1e-3, weight_decay = 1e-4),\n    loss = losses.mean_absolute_error,\n)\n\nmodel.normalizer.adapt(train)\n\nmodel.fit(train, epochs = 50,)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DiffusionModel(models.Model):\n\n    def reverser_diffusion(self, initial_noise, diffusion_steps):\n        num_images = initial_noise.shape[0]\n        step_size = 1.0 / diffusion_steps\n        current_images = initial_noise\n        for step in range(diffusion_steps):\n            diffusion_times = tf.ones((num_images, 1, 1, 1)) - step * step_size\n            noise_rates, signal_rates = self.diffusion_schedule(diffusion_times)\n            pred_noises, pred_images = self.denoise(\n                current_images, noise_rates, signal_rates, training = False\n            )\n            next_diffusion_times = diffusion_times - step_size\n            next_noise_rates, next_signal_rates = self.diffusion_schedule(\n                next_diffusion_times\n            )\n            current_images = (\n                next_signal_rates * pred_images + next_noise_rates * pred_noises\n            )\n        return pred_images","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DiffusionModel(models.Model):\n\n    def denormalize(self, images):\n        images = self.normalizer.mean + iamges * self.normalizer.variance**0.5\n        return tf.clip_by_value(images, 0.0, 1.0)\n    \n    def generate(self, num_images, diffusion_steps):\n        initial_noise = tf.random.normal(shape = (num_images, 64, 64, 3))\n        generated_images = self.reverse_diffusion(initial_noise, diffusion_steps)\n        generated_images = self.denormalize(generated_images)\n        return generated_images","metadata":{},"execution_count":null,"outputs":[]}]}